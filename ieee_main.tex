\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{natbib}

\newcommand{\PeakNet}{PeakNet}
\newcommand{\peaknet}{PeakNet}
\newcommand{\psocake}{Psocake}

\begin{document}

\title{\peaknet{}: Bragg peak finding in X-ray crystallography experiments with
U-Net}

\author{\IEEEauthorblockN{Cong Wang}
\IEEEauthorblockA{\textit{Linac Coherent Light Source} \\
\textit{SLAC National Accelerator Laboratory}\\
%% 2575 Sand Hill Road, Menlo Park, CA 94025, USA \\
cwang31@slac.stanford.edu}
\and
\IEEEauthorblockN{Po-nan Li*\thanks{* Performed this work in
a previous role at SLAC National Accelerator Laboratory}}
%% City, Country \\
\and
\IEEEauthorblockN{Jana Thayer}
\IEEEauthorblockA{\textit{Linac Coherent Light Source} \\
\textit{SLAC National Accelerator Laboratory}\\
%% 2575 Sand Hill Road, Menlo Park, CA 94025, USA \\
jana@slac.stanford.edu}
\and
\IEEEauthorblockN{Chun Hong Yoon}
\IEEEauthorblockA{\textit{Linac Coherent Light Source} \\
\textit{SLAC National Accelerator Laboratory}\\
%% 2575 Sand Hill Road, Menlo Park, CA 94025, USA \\
yoon82@slac.stanford.edu}
}

\maketitle

\begin{abstract}
Serial crystallography at X-ray free electron laser (XFEL) sources has
experienced tremendous progresses in achieving high data rate in recent times.
While this development offers potential to enable novel scientific
investigations, such as imaging faster molecular events, it also poses
challenges in regards to real-time data analysis, which may have to involve some
degree of data reduction to only save those containing actionable information on
disks.  If data reduction is not effective, it could directly result in a
substantial increase in facility budgetary requirements, or even hinder the
utilization of ultra-high repetition imaging techqniues.  Furthermore, an
additional challenge involves providing real-time feedback to users derived from
real-time data analysis.  Under the framework of serial crystallography, the
initial and critical step in real-time data analysis is finding X-ray Bragg
peaks from diffraction images.  To tackle this challenge, we present \peaknet{},
a Bragg peak finder that utilizes neural networks and runs about four times
faster than \psocake{} peak finder, while delivering significantly better
indexing rates and comparable number of indexed events.  We formulated the task
of peak finding into a semantic segmentation problem, which is then addressed by
using the classical U-Net architecture.  A key advantage of \peaknet{} is its
ability to scale linearly with respect to data volume, making it well-suited for
real-time serial crystallography data analysis at high data rates.  Additionally,
we identified a performance bottleneck that, if eliminated, would result in
scaling beyound linear capability on GPUs.
\end{abstract}

%% \begin{IEEEkeywords}
%% component, formatting, style, styling, insert
%% \end{IEEEkeywords}

\section{Introduction}

Serial crystallography with X-ray free electron lasers (XFEL) has enabled the
structural determination of three-dimensional macromolecules from radiation
damage-free samples at room temperature, an approach commonly known as
\textit{diffraction-before-destruction}
\citep{neutzePotentialBiomolecularImaging2000,
chapmanFemtosecondDiffractiveImaging2006,chapmanFemtosecondXrayProtein2011}.
Time-resolved serial crystallography at XFEL facilities, like the Linac Coherent
Light Source (LCLS), allows the investigation of biochemical reactions with
femtosecond-scale time resolutions.  This technique is typically referred to as
serial femtosecond crystallography (SFX), which has led to many signficiant
structural studies \citep{kupitzSerialTimeresolvedCrystallography2014,
nangoThreedimensionalMovieStructural2016,pandeFemtosecondStructuralDynamics2016a,
youngStructurePhotosystemII2016,sugaLightinducedStructuralChanges2017,
kernStructuresIntermediatesKok2018,ibrahimUntanglingSequenceEvents2020,
sugaTimeresolvedStudiesMetalloproteins2020} since the first published work at
LCLS \citep{aquilaTimeresolvedProteinNanocrystallography2012}.  In the meantime,
the data rate at XFEL facilities have also gradually increased from hundreds of
Hz to the MHz range, with the European X-ray Free Electron Laser (EuXFEL) being
the first MHz facility available to users and LCLS-II set to launch in 2023.

At the MHz data rate, novel real-time data analysis approaches are needed to
tackle two major challenges that arise in SFX experiments, namely data reduction
and real time feedback.  Firstly, data reduction aims to extract and compress
real-time actionable information by identifying important events, commonly
referred to as ``hits", and vetoing irrelevant ones from terabytes per second of
data streams.  One typical approach for SFX hit finding utilizes existing Bragg
peak finders, such as the Cheetah peak finder
\citep{bartyCheetahSoftwareHighthroughput2014}, the robust peak finder
\citep{hadian-jaziPeakfindingAlgorithmBased2017} or the \psocake{} peak finder
\citep{shinDataAnalysisUsing2018}.  Additionally, a neural networks-based SFX
hit finder was reported to achieved a processing rate of 1.3 kHz on a single GPU
\citep{keConvolutionalNeuralNetworkbased2018}.  Secondly, real-time feedback in
SFX experiments provides users with information on the experimental conditions
and allows them to make real-time decisions that can optimize the data
acquisition process.  For example, it's critical to fine-tune the hit rate to
maximize the usage of samples;  it's also important to know the current
diffraction limit, crystalline mosaicity, reciprocal space coverage, and other
revelant factors over time.  Therefore, hit finding alone is insufficient to
provide the necessary insights, making real-time Bragg peak finding crucial in
delivering fast and comprehensive feedbacks.  The previously mentioned peak
finder in \psocake{} runs at roughly 5 Hz on a data center CPU, which may result
in substantial costs when attempting to scale up the process.

In this work, we present \peaknet{} that addresses the problem of high data rate
peak finding by converting it into the task of peak segmentation using neural
networks.  To accomplish this goal, we propose to train a neural network model
to classify each individual pixel as either a peak pixel or not a peak pixel.
This is followed by recognizing a connected area of pixels as a single peak, a
task that can be readily accomplished through the connected component analysis
\citep{weaverCentrosymmetricCrossSymmetricMatrices1985}.  Subsequently, the peak
coordinates will be determined by computing the center of mass of all the pixels
that belong to the identified peak.  It's worth noting that the entire peak
finding process takes place on GPUs, offering a cost-effective option for
achieving scalability.  Concretely, our contributions can be summarized as
follows:

\begin{itemize}

    \item We introduce a deep neural network-based Bragg peak finder, named
    \peaknet{}, which can effectively and efficiently segment hundreds or even
    thousands of Bragg peaks with various peak profiles in detector images of
    any size.  Despite being trained on peaks labeled by an existing peak finder,
    we highlight that \peaknet{}'s capability is not limited by the peak finder
    used in labeling.

    \item We demonstrate the efficacy of \peaknet{} by evaluating its
    performance on large multi-panel ($1739 \times 1748$) and single-panel
    ($1920 \times 1920$) detector.  It significantly outperformed existing
    methods in terms of indexing rate, while delivering comparable number of
    indexed events.  We also finetuned the underlying U-Net architecture of
    \peaknet{} to strike an optimal balance between model efficacy and runtime
    performance, leading to a four times out-of-the-box processing speed than
    \psocake{} peak finder.

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related work}

Reliable and automatic peak finding algorithms have undergone multiple
iterations of development.  An early approach involved utilizing template
matching \citep{wilkinsonIntegrationSinglecrystalReflections1988a} based on
libraries of peak shapes, but this method was found to be slow and inefficient
in runtime, especially when dealing with peaks with low signal-to-noise ratios
(SNR).  The main obstacle lies in the localization of peaks and the tuning of
user parameters for pattern matching, compounded by the difficult task of
developing a comprehensive library of peak shapes.  Another influential approach
employed region-growing techniques
\citep{bolotovskySeedSkewnessMethodIntegration1995,
bartyCheetahSoftwareHighthroughput2014} to detect pixel areas with high
skewness.  In the context of serial crystallography with XFEL sources, the
efficacy of this method was diminished due to the lack of sufficient data to
provide reliable statistics, rendering it susceptible to outliers and less adept
in analyzing weak peaks at higher scattering angles, which are essential for
achieving atomic resolution in structure determination.

While template matching and region-growing tecnhiques require users to provide
priori information like threshold values, Robust Peak Finder (RPF)
\citep{hadian-jaziPeakfindingAlgorithmBased2017,
hadian-jaziDataReductionSerial2021} has demonstrated proficient peak finding
capabilities with minimal user inputs.  This techinuqe utilizes the Modified
Selective Statistical Estimator (MSSE) method to segment between background
pixels and actual peaks.  Furthermore, the RPF method can also parallelize the
processing of diffraction patterns, making it ideal for real-time data analysis.

\psocake{} is a software specifically designed to streamline high throughput
data reduction and analysis of XFEL experiments, and is routinely used at SLAC
National Accelerator laborator (SLAC) and Pohang Accelerator Laboratory (PAL).
The built-in peak-finding algorithm \citep{shinDataAnalysisUsing2018} includes
calibrating raw analog digital units (ADUs); applying optional background
correction and bad pixel masks; identifying possible peaks; calculating their
SNR; determining Bragg spot sizes; and selecting peaks based on size, total
intensity and SNR.

In recent years, neural network models have emerged as a promising avenue for
Bragg peak finding.  BraggNet \citep{sullivanBraggNetIntegratingBragg2019} is
the first method that demonstrates proficiency of neural network models,
specifically U-Net \citep{ronnebergerUNetConvolutionalNetworks2015}, in
accurately segmenting peak pixels, including weak peaks, from background pixels
in neutron crystallography data.  Specifically, BraggNet employed simulated
peaks to create training datasets, which underwent a number of preprocessing
steps, including centering and cropping to a specfic size and adding Poisson
noise.  It should be noted that BraggNet works on a single peak at a time within
a small 32 by 32 window, which deviates significantly from conventional Bragg
peak finding tasks that require extracting peak positions from images typically
with hundreds or thousands of pixels along one dimension.  Furthermore, another
neural network method for Bragg peak analysis was detailed in the work of
BraggNN \citep{liuBraggNNFastXray2021}, emphasizing the refinement of Bragg peak
positions without the need for explicit fitting of a profile function, such as
the pseudo-Voigt profile.  Likewise, BraggNN works on a single peak at a time
within a 11 by 11 window, performing regression to two variables representing
the peak position.  To the best of our knowledge, no existing neural network
based peak-finding models have demonstrated the ability to detect multiple peaks,
which is the primary goal we strive to achieve with \peaknet{}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}

% Summarize the method
% Breakdown
% - u-net
% - loss function
% - post process
% - labeling
%   - stream files, peak found and indexed
%   - label refinement

\peaknet{} uses a U-Net architecture to perform peak segmantation on diffraction
images, generating a heatmap of probabilities of a given pixel belonging to a
true peak.  A probability threshold is subsequently employed to translate the
heatmap into a binary mask or segmentation map, with a value of one indicating a
peak pixel and zero otherwise.  A connected component analysis
\citep{weaverCentrosymmetricCrossSymmetricMatrices1985} is then applied to
extract peak positions in image coordinates.  The entire peak finding process is
summarized in Fig. \ref{fig : peak finding}.  In this section, we present the
details in model training, comprising the specific U-Net architecture, the loss
function and the data labeling process.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]
{./figures/peaknet.method.pdf}
\caption{Peak finding process in \peaknet{}.}
\label{fig : peak finding}
\end{figure*}


\subsection{The segmentation model: U-Net}

Peak segmentaiton in \peaknet{} is achieved by the use of U-Net
\citep{ronnebergerUNetConvolutionalNetworks2015} with a reduced number of
feature channels applied in both the contracting and expanding paths, as
depicted in Fig. \ref{fig : unet}.  A single contracting layer contains two
stride-one and zero-padding $3 \times 3$ convlutional layers with a rectified
linear unit (ReLU) \citep{fukushimaCognitronSelforganizingMultilayered1975} and
an additional stride-two $2 \times 2$ max-pooling layer.  The number of feature
channels doubles with respect to its previous contracting layer.  Likewise, a
single expanding path contains a stride-two $2 \times 2$ transposed
convolutional layers concatenated with the corresponding feature map from the
contracting path.  This is followed by two stride-one $3 \times 3$ convolutional
layers connected to a ReLU activation function.  It is worth noting that the
feature map cropping may be necessary during the concatenation between feature
maps from two paths.  In the last layer, all 8 channels will be mapped to a
single channel through a $1 \times 1$ convolution.

\begin{figure*}[htbp]    % Insert the figure HERE and TOP
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]
{./figures/unet.pdf}
\caption{The U-Net architecture in \peaknet{}.}
\label{fig : unet}
\end{figure*}


\subsection{The loss function: focal loss}

A main technical issue in training U-Net for Bragg peak detection is the extreme
peak-background class imbalance (e.g., $> 10^3 : 1$), resulting in reduced
prediction accuracy.  This may not pose as a problem in previous peak finders
like BraggNet, which operates on a much smaller area of $32 \times 32$, whereas
\peaknet{} is trained on larger multiple panel detectors, such as the
Cornell-SLAC pixel array detector (CSPAD) \citep{hartCornellSLACPixelArray2012}
with a dimension of $194 \times 185$ for one of its panels.  Focal loss was
introduced to address the extreme class imbalance problem for object detectors
\citep{linFocalLossDense2018}.  It is defined as:

\begin{equation}
    \text{FL}(p_{\text{peak}}) = -\alpha \cdot p_{\text{background}}^\gamma
    \cdot \log{p_{\text{peak}}}
\end{equation}

Here, $p_{\text{peak}}$ and $p_{\text{background}}$ are the probabilities of a
pixel being a peak and a background, respectively, with $p_{\text{peak}} +
p_{\text{background}} = 1$.  $\gamma$ controls a modulating factor
$p_{\text{background}}$ and $\alpha$ is an additional modulating factor.  In
practice, numerical instability will often emerge in the calculation of
$p_\text{peak}(x) = e^{-\text{logit(x)}}$ given an output value $x$ from the
U-Net, where $\text{logit} (x) = \log{(1 + e^{-x})}$.  To bypass this issue,
logit needs to be rewritten as $\text{logit}(x) = a + \log{(e^{-a} + e^{-x-a})}$,
where $a = max(0, -x)$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}

\subsection{\peaknet{} on multi-panel detectors: Trained on panels but
predicting on assembled images.}

We demonstrated the possibility of \peaknet{} making prediction on assembled
images from a multi-panel detectors despite being trained on individual panels.
To facilitate this investigation, we utilized a multi-panel detector CSPAD,
which is widely used in serial crystallography experiments at LCLS.
Specifically, we used crystallographic data from the LCLS experiment
\textit{cxic0415} at run \textit{101} in the Coherent X-ray Imaging (CXI)
instrument, where the CSPAD deployed consists of 32 panels.  An individual
diffraction image recorded on CSPAD are conventionally saved in a stack of 64
mini-panels (half of a physical CSPAD panel).  For data labeling, we randomly
selected 268 mini-panels, which were labeled using the \psocake{} peak finder
with the default settings.  We then split the labeled data into 60\% training
set and 20\% validation set.  The remaining 20\% data were initially set aside
for testing purposes, but were not used due to the lack of an effecitve metrics,
which will be discussed later in the evaluation of our model's efficacy.  Our
test set included the first 5000 events of the run, which facilitated a faster
feedback loop compared with going through all events in the run.  Notably, we
didn't apply any image preprocessing, and thus \peaknet{} directly takes in an
diffraction image of its original size and outputs a segmentation map.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]
{./figures/label_to_predict_with_zoom.pdf}
\caption{(a) \peaknet{} input images and peak labels.  (b) \peaknet{} prediction
on an entire CSPAD image.  (c) A magnified view of a small region of the
detector.}
\label{fig : label and predict}
\end{figure*}

Fig. \ref{fig : label and predict} (a) displays labeled samples, with the input
mini-panel image on the left and pixel-wise labeled peaks on the right.  The
overall peak label is a binary mask that shares the same size as the input, with
a value of one indicating a peak pixel and zero otherwise.  Consequently, each
input consists of a $185 \times 194$ mini-panel from the CSPAD and a binary mask
of the same size.  Additionally, Fig.  \ref{fig : label and predict} (b) shows a
sample model prediction on an entire CSPAD image with a size of $1739 \times
1748$.  


\subsection{Examining \peaknet{}'s generalizability beyound the peak finder used
in labeling}

The current strategy for data labeling involves using an existing peak finder,
and it is important to evaluate whether any limitations of the peak finder used
in data labeling will affect the peak finding capability of \peaknet{}. One
specific limitation to investigate is the size dependency of the peak finder.
Notably, the peak size range is a user-defined input requested by the \psocake{}
peak finder. This works well when diffraction spots have consistent sizes.
However, detectors such as Rayonix have a large point spread function, which may
result in large peaks being ignored by the \psocake{} peak finder.  Consequently,
there is a concern about whether \peaknet{} will inherit the same limitations
since it is trained on \psocake{} peak labels.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]
{./figures/rayonix.pdf}
\caption{Peak finding on a Raynoix image using (c) \peaknet{} and (d) \psocake{}.  (a), (b), (c) and (d) are magnified views of some regions.}
\label{fig : rayonix}
\end{figure*}

Fig. \ref{fig : rayonix} presents a side-by-side comparison of peak detection on
a Rayonix image, with the \peaknet{} results displayed on the left and the
\psocake{} results on the right. Upon visual inspection of Fig. \ref{fig :
rayonix} (c) and (d), both \peaknet{} and \psocake{} were observed to detect a
considerable number of peaks, suggesting a potentially comparable performance
between the two methods.  However, upon closer inspection of the view near the
area slightly below the beamstop position, one obvious, reasonably sized Bragg
peak was observed but not detected by the \psocake{} peak finder, whereas
\peaknet{} successfully located this peak.  This finding provides direct
evidence that \peaknet{}'s peak finding capability is not strictly limited by
the peak finder used in the data labeling process.  In fact, \peaknet{} appears
to possess its own understanding of Bragg peaks, as evidenced by the exclusion
of a weak single Bragg peak-like spot near the upper edge of the image, as shown
in Fig. \ref{fig : rayonix} (a) and (b).  Therefore, it's important to note that
\peaknet{} is not merely a neural network replica of the \psocake{} peak finder
despite being trained on labels supplied by it.


\subsection{Model efficacy and runtime performance}

We consider model efficacy of a peak finder in two metrics: (1) indexing rate
and (2) the number of indexed events.  Table \ref{tb : perf} provides a
comparative analysis of two distinct datasets, CXI and MFX, showcasing the
outcomes obtained when processed using two peak finders, \psocake{} and
\peaknet{}.  The detectors employed for the respective datasets are CSPAD and
Rayonix.  The analyzed events for the CXI dataset span from 0 to 5000, whereas
the MFX dataset encompasses a range of 0 to 8998.  \psocake{} identified 2107
events in the CXI dataset and 465 in the MFX dataset, yielding indexing rates of
71.2\% and 84.5\% correspondingly.  In contrast, \peaknet{} discovered 1991
events in the CXI dataset and 430 in the MFX dataset, exhibiting superior
indexing rates of 78.6\% and 90.2\%, respectively.  Although both peak finders
exhibit varying levels of effectiveness, our evaluation has revealed that
\peaknet{} consistently achieves superior indexing rates across both datasets,
while also yielding comparable numbers of indexed events.  These results suggest
that \peaknet{} may represent a more reliable and efficient solution for the
analysis of such data, compared to the alternative peak finder.

To provide further context and justification for this efficacy measure, it is
important to note that conventional metrics like accuracy, precision and F-1
scores are not always well-defined in the context of peak finding, due to the
lack of actual ``ground truth".  This is because the peak labels used for
training and evaluation are derived from another peak finder, rather than being
uniquely determined in some fashion.  As a result, it is necessary to consider
alternative measures of model performance and reliability, such as the indexing
rate and the number of indexed events.  However, it is not surprising that
conventional metrics may remain a viable option when applied to synthetic data
generated by a simulator.

\begin{table}[htbp]
\caption{
    Peak finding and indexing results.
}
\label{tb : perf}
\centering
\begin{tabular}{ | l || c | c | }
    \hline
    Dataset           &  CXI   & MFX\\
    \hline
    Detector          & CSPAD  & Rayonix \\
    Events to analyze & 0-5000 & 0-8998 \\
    \hline
    \psocake{}: Found         &  2107   & 465  \\
    \psocake{}: Indexed       &  1501   & 393  \\
    \psocake{}: Indexing rate &  71.2\% & 84.5\% \\
    \hline
    \peaknet{}: Found         &  1991   & 430  \\
    \peaknet{}: Indexed       &  1565   & 388  \\
    \peaknet{}: Indexing rate &  78.6\% & 90.2\% \\
    \hline
\end{tabular}
\end{table}

Furthermore, while the runtime performance of \peaknet{} is excellent as
compared with other crystallography data analysis methods in Table \ref{tb :
runtime}, there is a caveat to consider.  Although \peaknet{} is designed as a
nearly end-to-end solution, with its neural networks returning a segmentation map
that represents the pixel-wise probability of being a peak from input
diffraction images, we must employ connected component analysis to convert the
segmentation maps into peak coordinates.  While the neural network runtime is
exceptionally fast, capable of processing 11 Rayonix images ($1920 \times 1920$)
in parallel on a 1080 Ti GPU in just 4ms (equivalent to 0.36 ms per image), the
additional time required for connected component analysis is considerably longer
and thus a significant runtime bottleneck in the current version of \peaknet{}.
In fact, this bottleneck processing time scales nearly linearly with respect to
the number of images, and it adds an additional 30ms of processing time for each
image despite running on the same GPU.  Practically speaking, the current
version of \peaknet{} runs at 49ms per Rayonix event on 1080 Ti, which is
actually 10 $\times$ faster than some diffraction image classification
algorithms.


\begin{table*}[htbp]
\caption{
    The runtime performance of diffraction image analysis algorithms measured on
    Rayonix images containing 3.7 megapixels.  We measured runtime performance
    of \psocake{} and \peaknet{} directly using Rayonix images.  For reference
    purposes, we also included another peak finding method RPF
    \citep{hadian-jaziPeakfindingAlgorithmBased2017,
    hadian-jaziDataReductionSerial2021} and two classification methods for X-ray
    diffraction data reduction. RPF runtime performance was originally measured
    on AGIPD 1M \citep{allahgholiAdaptiveGainIntegrating2019}.  The two
    classification methods were evaluated on 0.5 megapixel images using the CNN
    hit finder method \citep{keConvolutionalNeuralNetworkbased2018}, which was
    also used as a point of comparison in the ORB+MLP method
    \citep{rahmaniDataReductionXray2023}. A $*$ notation was used to indicate a
    linearly extrapolated processing time, but the real performance may vary
    depending on the specific hardware and the complexity of the underlying
    algorithm.
}
\label{tb : runtime}
\centering
\begin{tabular}{  | l || l | l | c | c | }
    \hline
    Method      &  Task & Hardware & Image size           & Time (ms/event)  \\
    \hline
    RPF         &  Peak Finding & Intel E5-2698 & 1024 $\times$ 1024 & $\sim$120.0            \\
                &               &               & 1920 $\times$ 1920 &
                $\sim$421.8*            \\
    \hline
    \psocake{}  &  Peak Finding & Intel E5-2620 & 1920 $\times$ 1920 & 200.0             \\
    \hline
    \textbf{\peaknet{}}  &  Peak Finding & NVIDIA 1080 Ti & 1920 $\times$ 1920 &
    \textbf{49.0}            \\
    \hline
    CNN hit finder  & Classification & NVIDIA 1080 Ti &  720 $\times$ 720 & 0.8 \\
                                                     & &                & 1920
                                                      $\times$ 1920 & 5.6* \\
    \hline
    ORB+MLP  & Classification & Intel Core i5  & 720 $\times$ 720 & 50.0 \\
                                                     & &                & 1920
                                                      $\times$ 1920 & 355.6* \\
    \hline
\end{tabular}
\end{table*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}

In this paper, we introduced \peaknet{}, a deep learning-based peak finder that
efficiently tackles the Bragg peak finding problem as a semantic segmentation
task. The U-Net architecture of \peaknet{} has been optimized to achieve an
ideal balance between efficacy and runtime performance, resulting in a
processing speed four times faster than the \psocake{} peak finder while
maintaining superior indexing rates and a comparable number of indexed events. A
notable bottleneck in the current version of \peaknet{} is the connected
component analysis, which scales linearly with input data volume, whereas the
neural network portion scales beyond linear capability on GPUs, limited largely
by GPU memory. It is worth mentioning that the current data reduction concept
primarily focuses on processing single events as quickly as possible, centering
the design principle on CPUs. However, with neural networks, we propose a new
direction towards batch image processing on GPUs, exemplified by \peaknet{} in
the context of serial crystallography.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgment}

The project was conceived by J.B.T and C.H.Y. Earlier versions of the U-Net
models were tested by P.L. under the supervision of C.H.Y.  The experiments were
designed by C.W with inputs from C.H.Y.  C.W prepared the datasets, labeled
experimental data, and trained and evaluated the refined neural network model.
The manuscript was written by C.W and C.H.Y with input from all authors.  This
material is based upon work supported by the U.S.  Department of Energy, Office
of Science, Office of Basic Energy Sciences under Award Number FWP-100643.  Use
of the Linac Coherent Light Source (LCLS), SLAC National Accelerator Laboratory,
is supported by the U.S. Department of Energy, Office of Science, Office of
Basic Energy Sciences under Contract No.  DE-AC02-76SF00515.

\bibliographystyle{plainnat}
\bibliography{bibliography.bib}

\end{document}

